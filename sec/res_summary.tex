\subsection{Summary}
\label{sec:res_summary}

\begin{table}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{c}{Data set} & \multicolumn{3}{c}{Model type} \\
\midrule
Name & Examples & Linear model & Feedforward DNN & Multi-input DNN \\
\midrule
Celebrities & 46,986 & 48.84\% & 70.29\% & 65.16\% \\
Politicians & 94,919 & 54.17\% & 64.75\% & 65.34\% \\
Companies & 254,059 & 59.64\% & 70.07\% & 73.52\% \\
Combined & 863,004 & 51.69\% & 55.50\% & 68.42\% \\
\bottomrule
\end{tabular}
\caption{Summary of results for classification task}
\label{tab:summary_classification}
\end{table}

\structure{Description of performance evolution for classification task}
\outline{DM1 always performs better than linear model}
\outline{Thus, model for structured inputs benefits from adding layers of
abstraction}
\outline{Of course, these performance gains come at the cost of interpretability
(black-box model)}
\outline{Adding texts as additional inputs leads to performance increases for
all data sets except celebrities}
\outline{Celebrities: DM2 still much better than linear model}
\outline{Seems like data set is too small to make sense of additional inputs}
\outline{Magnitude of performance gain increases with data set size}
\outline{This is intuitive, since better features can be learned from a larger
set of words}
\outline{Previous section: class accuracy increases with more labeled examples
(even if data set is imbalanced)}
\outline{Overall, results are not bad but leave room for further improvements}
\outline{Results suggest that adding more data (esp., for smaller classes) could
further increase class accuracy}
\outline{Furthermore, finding data for class 6 (more than 10,000 retweets) is difficult}
\outline{Realignment of classes (combine classes 5 and 6) would be a plausible solution}

\begin{table}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{c}{Data set} & \multicolumn{3}{c}{Model type} \\
\midrule
Name & Examples & Linear model & Feedforward DNN & Multi-input DNN \\
\midrule
Celebrities & 46,986 & 3,490.21 & 2,345.91 & 3,286.16 \\
Politicians & 94,919 & 482.81 & 414.68 & 447.61 \\
Companies & 254,059 & 24.66 & 20.57 & 19.41 \\
Combined & 863,004 & 579.26 & 549.93 & 401.52 \\
\bottomrule
\end{tabular}
\caption{Summary of results for regression task}
\label{tab:summary_classification}
\end{table}

\structure{Description of performance evolution for regression task}
\outline{Similar results as for classification}
\outline{Huge performance increase on combined data set when adding tweet content
(27\% decrease in error)}
\outline{Data requirements seem to even higher as perf decreases on politician
data set and only slightly increases for companies}
\outline{Scale of possible engagement is wide-ranging which complicates MAE
interpretation}
\outline{Example: being 400 off has different meaning for zero and 10,000 retweets}
